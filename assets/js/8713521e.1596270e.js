"use strict";(globalThis.webpackChunktemp_docusaurus_init=globalThis.webpackChunktemp_docusaurus_init||[]).push([[383],{374:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"instructor-guide","title":"Instructor Guide: Physical AI & Humanoid Robotics","description":"This guide provides instructors with resources, teaching notes, and assessment rubrics for effectively delivering the \\"Physical AI & Humanoid Robotics: From Simulation to Reality\\" course.","source":"@site/docs/instructor-guide.md","sourceDirName":".","slug":"/instructor-guide","permalink":"/AI-Humanoid-Book/docs/instructor-guide","draft":false,"unlisted":false,"editUrl":"https://github.com/specifykit/ai-native-book/tree/main/docs/instructor-guide.md","tags":[],"version":"current","frontMatter":{},"sidebar":"mainSidebar","previous":{"title":"Glossary","permalink":"/AI-Humanoid-Book/docs/glossary"},"next":{"title":"ROS 2 Python Cheat Sheet","permalink":"/AI-Humanoid-Book/docs/student-resources/ros2_python_cheat_sheet"}}');var o=i(4848),r=i(8453);const t={},l="Instructor Guide: Physical AI & Humanoid Robotics",c={},d=[{value:"Course Overview",id:"course-overview",level:2},{value:"Teaching Notes by Module",id:"teaching-notes-by-module",level:2},{value:"Module 1: The Robotic Nervous System",id:"module-1-the-robotic-nervous-system",level:3},{value:"Module 2: The Digital Twin",id:"module-2-the-digital-twin",level:3},{value:"Module 3: The AI Robot Brain",id:"module-3-the-ai-robot-brain",level:3},{value:"Module 4: Vision-Language-Action",id:"module-4-vision-language-action",level:3},{value:"Assessment Rubrics",id:"assessment-rubrics",level:2},{value:"General Criteria",id:"general-criteria",level:3},{value:"Project-Specific Rubrics",id:"project-specific-rubrics",level:3},{value:"Additional Instructor Resources",id:"additional-instructor-resources",level:2}];function a(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"instructor-guide-physical-ai--humanoid-robotics",children:"Instructor Guide: Physical AI & Humanoid Robotics"})}),"\n",(0,o.jsx)(e.p,{children:'This guide provides instructors with resources, teaching notes, and assessment rubrics for effectively delivering the "Physical AI & Humanoid Robotics: From Simulation to Reality" course.'}),"\n",(0,o.jsx)(e.h2,{id:"course-overview",children:"Course Overview"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Target Audience"}),": Students, AI practitioners, and enthusiasts possessing foundational Python and AI/ML knowledge."]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Course Goal"}),": Provide comprehensive, hands-on guidance for building, simulating, and controlling intelligent embodied systems interacting with physical environments."]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Key Learning Outcomes"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Master ROS 2 for robotic control."}),"\n",(0,o.jsx)(e.li,{children:"Construct digital twins using Gazebo, Unity, and NVIDIA Isaac Sim."}),"\n",(0,o.jsx)(e.li,{children:"Integrate AI with robotics, including perception and navigation."}),"\n",(0,o.jsx)(e.li,{children:"Develop Vision-Language-Action (VLA) systems using LLMs and voice control."}),"\n",(0,o.jsx)(e.li,{children:"Implement capstone autonomous humanoid robot."}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"teaching-notes-by-module",children:"Teaching Notes by Module"}),"\n",(0,o.jsx)(e.h3,{id:"module-1-the-robotic-nervous-system",children:"Module 1: The Robotic Nervous System"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Focus"}),": ROS 2 foundations and robot modeling (URDF). Essential for all subsequent modules."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Key Concepts"}),": ROS 2 nodes, topics, services, actions, parameters. URDF links, joints, visuals, collisions."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Discussion Points"}),":","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Why middleware like ROS 2 is necessary for robotics?"}),"\n",(0,o.jsx)(e.li,{children:"Distinctions between ROS 1 and ROS 2 (emphasize real-time, security, DDS)."}),"\n",(0,o.jsx)(e.li,{children:"Importance of accurate robot modeling."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Common Pitfalls"}),": Environment setup issues (sourcing, dependencies), XML syntax errors in URDF."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Activity Ideas"}),":","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["Live demonstration of ",(0,o.jsx)(e.code,{children:"rqt_graph"}),"."]}),"\n",(0,o.jsx)(e.li,{children:"Challenge students modeling simple objects (e.g., furniture) in URDF."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"module-2-the-digital-twin",children:"Module 2: The Digital Twin"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Focus"}),": Simulation environments (Gazebo, Unity, Isaac Sim). Bridging URDF to simulation."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Key Concepts"}),": Gazebo components, physics engines, sensor simulation. Unity ",(0,o.jsx)(e.code,{children:"ArticulationBody"}),", ROS-TCP-Connector."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Discussion Points"}),":","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:'The "sim-to-real" gap and mitigation strategies.'}),"\n",(0,o.jsx)(e.li,{children:"Trade-offs between different simulators (Gazebo for physics, Unity for graphics, Isaac Sim for AI/synthetic data)."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Common Pitfalls"}),": Physics parameters leading to unstable simulations, ROS 2-simulator communication issues."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Activity Ideas"}),":","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Challenge students creating simple obstacle courses in Gazebo."}),"\n",(0,o.jsx)(e.li,{children:"Demonstrate simple control loops where ROS 2 nodes control Unity-simulated joints."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"module-3-the-ai-robot-brain",children:"Module 3: The AI Robot Brain"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Focus"}),": Advanced perception (Isaac ROS VSLAM) and autonomous navigation (Nav2)."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Key Concepts"}),": VSLAM principles, hardware acceleration, costmaps, global/local planning."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Discussion Points"}),":","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"How GPUs accelerate perception tasks."}),"\n",(0,o.jsx)(e.li,{children:"Docker's role in managing complex dependencies for AI robotics."}),"\n",(0,o.jsx)(e.li,{children:"Challenges in real-time mapping and localization."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Common Pitfalls"}),": Docker setup issues, Nav2 parameter tuning, sensor data misconfiguration."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Activity Ideas"}),":","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Guide students through tuning Nav2 parameters and observing effects."}),"\n",(0,o.jsx)(e.li,{children:"Discuss different VSLAM algorithms and their suitability for various environments."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"module-4-vision-language-action",children:"Module 4: Vision-Language-Action"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Focus"}),": Integrating voice control (Whisper) and cognitive planning (LLMs) with robotics."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Key Concepts"}),": ASR, NLU, prompt engineering, LLM-based planning, action orchestration."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Discussion Points"}),":","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Ethical implications of LLM-controlled robots."}),"\n",(0,o.jsx)(e.li,{children:"Future of human-robot natural language interaction."}),"\n",(0,o.jsx)(e.li,{children:"Limitations of current LLM planners."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Common Pitfalls"}),": LLM prompt engineering, API key management, latency issues."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Activity Ideas"}),":","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Brainstorm new robot skills that LLMs could orchestrate."}),"\n",(0,o.jsx)(e.li,{children:"Have students critique robot responses to ambiguous voice commands."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"assessment-rubrics",children:"Assessment Rubrics"}),"\n",(0,o.jsx)(e.h3,{id:"general-criteria",children:"General Criteria"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Code Quality"}),": Readability, comments, adherence to ROS 2 best practices."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Functionality"}),": Code executes without errors, meets requirements."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Understanding"}),": Ability to explain concepts, troubleshoot issues."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Problem Solving"}),": Approach to debugging, creative solutions."]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"project-specific-rubrics",children:"Project-Specific Rubrics"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Module Project 1 (Voice-Controlled Robot Arm - Conceptual):"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Environment Setup"}),": ROS 2 correctly installed and sourced."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"URDF Model"}),": Robot model is valid and visualized in Rviz2."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS 2 Nodes"}),": Basic publisher/subscriber nodes are functional."]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Module Project 2 (Simulated Robotic Arm in Gazebo):"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Gazebo World"}),": Custom Gazebo world created and functional."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Robot Spawning"}),": URDF arm correctly spawned and visible in Gazebo."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS 2 Control"}),": Arm controllable via ROS 2 commands in Gazebo."]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Module Project 3 (Autonomous Robot Navigation in Isaac Sim):"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac Sim Setup"}),": Isaac Sim environment and robot configured."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"VSLAM Implementation"}),": VSLAM running and providing localization."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Nav2 Integration"}),": Robot navigates autonomously to goals."]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Module Project 4 (Autonomous Humanoid with Voice Control - Capstone):"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"VLA Pipeline"}),": All components (Whisper, LLM, Nav2, Isaac Sim) integrated."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Command Execution"}),": Humanoid executes multi-step voice commands."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Error Handling"}),": Basic error handling implemented."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"additional-instructor-resources",children:"Additional Instructor Resources"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.em,{children:"(This section will be populated with links to external teaching materials, additional exercises, and advanced topics as content evolves.)"})})]})}function u(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(a,{...n})}):a(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>t,x:()=>l});var s=i(6540);const o={},r=s.createContext(o);function t(n){const e=s.useContext(r);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:t(n.components),s.createElement(r.Provider,{value:e},n.children)}}}]);